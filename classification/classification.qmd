---
title: "assessment-checking"
format: html
editor: visual
editor_options: 
  chunk_output_type: console
---

# TODO

-   Convert() function does a lot of tweaks - can these go in a .csv lookup file?
-   Unit test for mean_alkalinity
-   Unit test for RICT
-   Unit test for DARLEQ
-   List where data is saved from previous years and combine into single dataset?

```{r}
# devtools::install_github("ecodata1/hera")
library(hera)
library(tidyverse)
library(arrow)
library(readxl)
```

# LIMS Data

Open files of pre-fetched data from LIMS (provided by LIMS Admin). Data provided by LIMS Admin needs 'test number' column. Test number is used to uniquely identify/join taxa and abundance values in the convert() function.

## Ecology

```{r}
user <- Sys.info()["user"]
path <- paste0(
  "C:/Users/",
  user,
  "/OneDrive - Scottish Environment Protection Agency/DNA Data/Readiness Data/classification/latest-lims-data.csv"
)

lims_eco <- readr::read_csv(
  path
)
lims_eco$HAS_FLAGS...16 <- NULL
lims_eco$HAS_FLAGS...20 <- NULL

lims_eco <- filter(lims_eco, TEMPLATE != "FORMAL")

lims_eco <- filter(lims_eco, ANALYSIS %in% c(
  "PAC",
  "RIVER_DIATOMS",
  "DIATOMS",
  "FW_INVERTS_FIELD",
  "INVERTS_FIELD",
  "MTL_TL5",
  "MTL_TL4",
  "LAB_INVERTS",
  "INVERTS_TL2",
  "INVERTS_TL5"
))

# Remove family level results if MTL present
check <- lims_eco %>%
  select(ANALYSIS, ORIGINAL_SAMPLE) %>%
  distinct() %>%
  filter(ANALYSIS %in% c("MTL_TL5", "MTL_TL4", "LAB_INVERTS","INVERTS_TL2","INVERTS_TL5")) %>%
  group_by(ORIGINAL_SAMPLE) %>%
  summarise(n = n()) %>%
  filter(n > 1)

remove <- lims_eco %>%
  filter(ORIGINAL_SAMPLE %in% check$ORIGINAL_SAMPLE &
    ANALYSIS %in% c("LAB_INVERTS","INVERTS_TL2"))

rm(check)

lims_eco <- lims_eco %>% 
  filter(!SAMPLE_NUMBER %in% unique(remove$SAMPLE_NUMBER))
```

Change some column names that are different in LIMS export versus the expected output in LIMS Data explorer output.

```{r}
# Need to rename columns from LIMS extract to match expected names for the
# convert() function below
# lims_eco$REPORTED_NAME <-  lims_eco$DETERMINAND_NAME
# lims_eco$FORMATTED_ENTRY <-  lims_eco$RESULT
# lims_eco$DESCRIPTION <- lims_eco$SAMPLING_POINT_DESCRIPTION
lims_eco$SAMPLE_NUMBER <- lims_eco$ORIGINAL_SAMPLE
```

Convert LIMS data into standard data format for hera package so metrics etc can be calculated.

```{r}
lims_eco <- hera::convert(lims_eco,
  convert_to = "hera",
  convert_from = "sepa_lims"
)
```

## Merge

```{r}
lims_data <- lims_eco
```

# Recovered data

```{r}
# Recovered data  ----------------------
user <- Sys.info()["user"]
path <- paste0(
  "C:/Users/",
  user,
  "/OneDrive - Scottish Environment Protection Agency/DNA Data/Readiness Data/analytical-data/all_data_clean.arrow"
)

ds <- open_dataset(path,
  format = "arrow"
)

eco_data <- ds %>%
  filter(parameter %in% c(
    "River Family Inverts",
    "River Diatoms",
    "SURVEY_INV"
  )) %>%
  collect()

# Sometimes you know, there's just duplicate results (but not results numbers).
# Need better way to deal with these (possibly will remove from 'tidied'
# archived data)? There's about 12 duplicate results - none of which have any
# impact if removed.
eco_data <- distinct(eco_data)

eco_data$parameter[is.na(eco_data$parameter)] <- 
  eco_data$analysis_repname[is.na(eco_data$parameter)]

eco_data <- dplyr::filter(eco_data, parameter %in% c(
  "River Family Inverts",
  "River Diatoms",
  "SURVEY_INV"
))

eco_data$parameter[eco_data$parameter == "SURVEY_INV"] <- "River Family Inverts"

eco_data$question[eco_data$question ==
  "% Boulders/Cobbles"] <- "boulders_cobbles"
eco_data$question[eco_data$question ==
  "% Pebbles/Gravel"] <- "pebbles_gravel"
eco_data$question[eco_data$question ==
  "% Sand"] <- "sand"
eco_data$question[eco_data$question ==
  "% Silt/Clay"] <- "silt_clay"
eco_data$question[eco_data$question ==
  "River Width (m)"] <- "river_width"
eco_data$question[eco_data$question ==
  "Mean Depth (cm)"] <- "mean_depth"

# Get all chem alk data pre sept 2019
path <- paste0(
  "C:/Users/",
  user,
  "/OneDrive - Scottish Environment Protection Agency/DNA Data/Readiness Data/analytical-data/ALK_RESULTS_CHEM_SEP19.xlsx"
)

alk_results_sep_19 <- readxl::read_excel(path)

alk_results_sep_19$DATE_TAKEN <- substr(alk_results_sep_19$DATE_TAKEN, 1, 10)
alk_results_sep_19$DATE_TAKEN <- as.Date(alk_results_sep_19$DATE_TAKEN)

names(alk_results_sep_19) <- tolower(names(alk_results_sep_19))
alk_results_sep_19 <- select(
  alk_results_sep_19,
  location_code,
  media,
  date_taken,
  sample_no,
  test_number,
  purpose,
  wfd_purpose,
  determinand_code,
  determinand,
  result,
  units_code,
  sign,
  loq_result,
  loq_sign
)

alk_data <- hera::convert(alk_results_sep_19, 
                          convert_from = "sepa_chem",
                          convert_to = "hera")


predictors <- utils::read.csv(
  system.file("extdat",
    "predictors.csv",
    package = "hera"
  ),
  stringsAsFactors = FALSE, check.names = FALSE
)
predictors$location_id <- as.character(predictors$location_id)

alk_data <- filter(alk_data, location_id %in% unique(predictors$chemistry_site))

eco_data$date_taken <- as.Date(eco_data$date_taken)
eco_data$test_number <- as.character(eco_data$test_number)
eco_data$location_id <- as.character(eco_data$location_id)
eco_data$sample_id <- as.character(eco_data$sample_id)

alk_data$units <- as.character(alk_data$units)
alk_data$response <- as.character(alk_data$response)
alk_data$test_number <- as.character(alk_data$test_number)
alk_data$location_id <- as.character(alk_data$location_id)
alk_data$sample_id <- as.character(alk_data$sample_id)

recovered_data <- bind_rows(eco_data, alk_data)
```

# Combine Data

```{r}
data <- bind_rows(recovered_data, lims_data)
data$parameter[is.na(data$parameter)] <- "PAC"

rm(recovered_data, eco_data, lims_data, lims_eco, alk_data)
```

# Filter

Only core surveillance sites to speed up testing and filter out ecology old samples.

```{r}
data$year <- lubridate::year(data$date_taken)
data <- data %>% filter(year >= 2016 | parameter == "PAC")
```

# Predictors

Filter RICT predictors.

```{r, message=FALSE}
predictors$date <- as.Date(predictors$date)
# use latest 'version' for each location_id
predictors <- arrange(predictors, desc(date))
predictors <- select(
  predictors,
  alkalinity,
  location_id,
  grid_reference,
  chemistry_site,
  altitude,
  slope,
  discharge_category,
  dist_from_source
)
predictors <- predictors[!duplicated(predictors$location_id), ]

data <- left_join(data, predictors, by = c("location_id"))

rm(predictors)
```

# Calculate Alkalinity

If alkalinity required calculate.

```{r}
# to reduce data size, only use chem data that is needed for ecology sites
taxa_data <- data[data$parameter != "PAC", ]
chem_data <- data[data$parameter == "PAC", ]
chem_data <- chem_data[chem_data$location_id %in%
  unique(taxa_data$chemistry_site), ]
data <- bind_rows(taxa_data, chem_data)

rm(taxa_data, chem_data, alk_results_sep_19)

# write.csv(data,"vignettes//data//2025-04-11-data.csv", row.names = FALSE)
# data <- read.csv("vignettes//data///2024-07-05-data.csv")

data$alkalinity <- NULL

# write.csv(data,"vignettes//data//data-no-alk.csv", row.names = FALSE)
# data <- read.csv("vignettes//data//data-no-alk.csv")

alkalinity <- hera:::mean_alkalinity(data)

# write.csv(alkalinity,"vignettes//data//2024-07-05-alkalinity.csv", row.names = FALSE)
# alkalinity <- read.csv("vignettes//data//2024-07-05-alkalinity.csv")
# alkalinity <- read.csv("vignettes//data//alkalinity.csv")
# alkalinity <- distinct(alkalinity)
# alkalinity <- alkalinity[!is.na(alkalinity$alkalinity), ]

# Remove none ecology data
data <- data[!is.na(data$location_id), ]
data <- data[data$parameter %in% c(
  "River Family Inverts",
  "River Diatoms"
), ]

data <- left_join(data,
  alkalinity,
  by = join_by("sample_id" == "sample_number")
)

# what sites with chemistry site but no alkalinity data?
missing_alk <- data[
  is.na(data$alkalinity),
]
missing_alk <- missing_alk[missing_alk$analysis_repname %in% c(
  "Diatom Taxa","DIATOMS",
  "Invert Taxa Family Lab", "RIVER_DIATOMS", "LAB_INVERTS","INVERTS_TL2"
), ]
miss_alk_test <- unique(missing_alk[missing_alk$year > 2019, c(
  "location_id",
  "location_description",
  "chemistry_site"
)])

miss_alk_test <- filter(miss_alk_test, !is.na(chemistry_site))

missing_gis <- data[data$analysis_repname %in%
  c("LAB_INVERTS","INVERTS_TL2") &
  is.na(data$discharge_category), ]
missing_gis[, c(
  "location_id",
  "location_description"
)] %>% unique()


# Some samples have field data from recovered data but lab data from LIMS.
# Based on date and location can we link these?
# Currently, field data without matching sample_id with lab data is removed.
# So, we need to give the matching field and lab data the same sample_id before this happens.
same_date <- data %>%
  filter(parameter == "River Family Inverts") %>%
  summarise(
    sample_id = unique(sample_id), n = length(unique(sample_id)),
    .by = c(location_id, date_taken)
  ) %>%
  filter(n > 1)

# remove parent samples that only have field data (and therefore alk not
# calculated)
eco_missing_alk <- data$sample_id[data$question == "pebbles_gravel" &
  is.na(data$alkalinity)]
data <- data[!data$sample_id %in% eco_missing_alk, ]

# Some samples taken before Sept 2019 don't have alkalinity, but these sites
# haven't been sampled since Sept 2019 - so therefore these samples can be
# removed
eco_missing_alk2 <- data[data$question == "Taxon name" &
  is.na(data$alkalinity), ]
eco_missing_alk2$location_id %>% unique()

data <- data[!data$sample_id %in% unique(eco_missing_alk2$sample_id), ]
```

# Classification

Run classification

## Classify

```{r, message=FALSE}
# write.csv(data,"vignettes//data//2024-03-18-data-v2.csv", row.names = FALSE)
# write.csv(data,"vignettes//data//2024-07-05-data-v2.csv", row.names = FALSE)
# data <- read.csv("vignettes//data//2024-07-05-data-v2.csv")
# data <- read.csv("vignettes//data//2024-03-18-data-v2.csv")
# data <- read.csv("vignettes//data//2024-03-18-data.csv")

data <- data[!is.na(data$grid_reference), ]
data <- data[data$grid_reference != "", ]

# Remove invert field survey if no matching invert sample
# data <- data %>%  filter(location_id == 134491)
field_only <- data %>%
  filter(data$analysis_repname %in% c(
    "Invert Physical Data",
    "LAB_INVERTS",
    "INVERTS_TL2",
    "MTL_TL5",
    "MTL_TL4",
    "INVERTS_TL5"
  )) %>%
  select(sample_id, analysis_repname) %>%
  distinct() %>%
  group_by(sample_id) %>%
  mutate(length = n()) %>%
  filter(analysis_repname == "Invert Physical Data", length == 1)

data <- data %>%
  left_join(field_only,
    by = join_by(
      sample_id,
      analysis_repname
    )
  ) %>%
  filter(is.na(length))

data <- mutate(data, year = lubridate::year(date_taken))
data <- data[data$year < 2025, ]
data <- dplyr::group_by(data, location_id, parameter) %>%
  dplyr::mutate(max_year = max(year))
data <- ungroup(data)

# only planned ecology samples (adhoc chemistry samples used for alkalinity
# average to agree with historic procedure)
data <- filter(data, purpose %in% c("SCHED", "Planned"))
# In case 'data' variable gets written over by other scripts
test_data <- data
results <- map_df(c(2019, 2020, 2021, 2022, 2023, 2024), function(class_year) {
  ids <- unique(data[data$max_year == class_year, c("sample_id", "parameter")])
  filter_data <- inner_join(data,
    ids,
    by = join_by(sample_id, parameter)
  )

  # Filter data-----------------------------------------------------------------
  # We only want samples that pass our criteria (season, number of samples etc)
  filtered_data <- filter_data %>%
    filter(year <= class_year) %>%
    hera:::filter_samples(classification_year_data = FALSE)
  wfd_results <- map_df(split(filtered_data, filtered_data$location_id),
    function(location) {
      message(unique(location$location_id))
      wfd_result <- assess(location,
        name = c(
          "DARLEQ3",  
          "RICT"
        )
      )
    },
    .progress = TRUE
  )
})
```

# Filter

```{r, message=FALSE}
# Filter out the predicted values and sample level results. We only want the
# location level results
results <- results[!is.na(results$location_id), ]

# write.csv(results,
# file = "vignettes\\data\\sample-classification-2023-final-v2.csv",
# row.names = FALSE)
# write.csv(results,
# file = "vignettes\\data\\sample-classification-2023-final.csv",
# row.names = FALSE)
# results <-
# read.csv(file = "vignettes\\data\\sample-classification-2023-final.csv")

results$location_id <- as.character(results$location_id)

results_filtered <- filter(
  results,
  question %in% c(
    "CoCH",
    "CoCG",
    "CoCM",
    "CoCP",
    "CoCB",
    "Class",
    "EQR",
    "Years included",
    "Comments",
    "Suit Code",
    "Suit Text"
  ),
  is.na(sample_id)
) %>%
  select(-sample_id)

# Pivot results to make them look nice
results_filtered <- pivot_wider(results_filtered,
  names_from = question,
  values_from = response
)


results_filtered <- results_filtered %>%
  mutate(
    parameter = ifelse(parameter == "Macroinvertebrates (ASPT)",
      "Macroinvertebrates (ASPT) - Rivers",
      parameter
    ),
    parameter = ifelse(parameter == "Macroinvertebrates (NTAXA)",
      "Macroinvertebrates (NTAXA) - Rivers",
      parameter
    ),
    parameter = ifelse(parameter == "Phytobenthos (diatoms)",
      "Phytobenthos (diatoms) - Rivers",
      parameter
    )
  )

```

# NMP

Add NMP to get WBIDs?

```{r}
user <- Sys.info()["user"]
path <- paste0(
  "C:/Users/",
  user,
  "/OneDrive - Scottish Environment Protection Agency/DNA Data/Readiness Data/classification/INV DIAT RAT NMP24 FINAL 23-04-24.xlsx"
)

nmp <- readxl::read_xlsx(
  path =
    path, sheet = "2024 FRESHWATER RIVER LOCH NMP"
)

# Fix issue with duplicates in NMP
nmp_diatoms <- filter(nmp, !is.na(`REG PURPOSE-DIAT`))
nmp_diatoms$`REG Mon Reason` <- nmp_diatoms$`REG PURPOSE-DIAT`
nmp_diatoms <- nmp_diatoms[!duplicated(nmp_diatoms$`Sample Point code`), ]


nmp_inverts <- filter(nmp, !is.na(`REG PURPOSE-INV`))
nmp_inverts$`REG Mon Reason` <- nmp_inverts$`REG PURPOSE-INV`
nmp_inverts <- nmp_inverts[!duplicated(nmp_inverts$`Sample Point code`), ]


nmp_diatoms$ANALYSIS <- "DIATOMS"
nmp_inverts$ANALYSIS <- "INVERTS"
nmp <- bind_rows(nmp_diatoms, nmp_inverts)
```

# Join NMP

```{r}
nmp <- select(nmp,
  "location_id" = `Sample Point code`,
  "wbid" = WBID,
  analysis = ANALYSIS,
  #  "replocs_check" = `CHK REPLOCS`,
  "mon_purp" = `REG Mon Reason`,
  DESC = `Sample Point Description`,
  "Local office" = "LOCAL OFFICE"
)

diatoms <- nmp[nmp$analysis == "DIATOMS", ]
diatoms$analysis <- "Phytobenthos (diatoms) - Rivers"
inverts <- nmp[nmp$analysis == "INVERTS", ]

aspt <- inverts
ntaxa <- inverts
aspt$analysis <- "Macroinvertebrates (ASPT) - Rivers"
ntaxa$analysis <- "Macroinvertebrates (NTAXA) - Rivers"
all_nmp <- bind_rows(aspt, ntaxa, diatoms)
all_nmp$location_id <- as.character(all_nmp$location_id)
all_nmp$wbid <- as.character(all_nmp$wbid)
results_filtered <- left_join(results_filtered, all_nmp, by = join_by(
  location_id,
  parameter == analysis
))
```

# Previous Class

Join 2023 classification results based on WB

```{r}
user <- Sys.info()["user"]
path <- paste0(
  "C:/Users/",
  user,
  "/OneDrive - Scottish Environment Protection Agency/DNA Data/Readiness Data/classification/readiness.csv"
)

readiness <- read.csv(file = path, 
                      stringsAsFactors = FALSE, 
                      check.names = FALSE)


readiness <- readiness %>%   filter(`Analysis Type` %in% c("INVERTS", "DIATOMS"))

readiness <- select(readiness, nmp_wbid,
                    `Sampling Point`,
                    `Analysis Type`,
                    `REG Mon Purps (combined)`,
                    `LOCAL OFFICE`) %>%  
  distinct() %>% 
  filter(!is.na(nmp_wbid))
# 
# readiness <- readiness %>% 
#   pivot_wider(names_from = `Analysis Type`, values_from = `REG Mon Purps (combined)`)
# 

# remove duplicates (incorrect wbid / sampling point combination from NMP)
select(readiness, nmp_wbid, `Sampling Point`) %>% 
    distinct() %>% 
group_by(`Sampling Point`) %>% 
  mutate(n_count = n()) %>%  filter(n_count > 1)


readiness <- filter(readiness, 
                    `Sampling Point` != 121293 &
                      nmp_wbid != 10145)


readiness <- filter(readiness, 
                    `Sampling Point` != 302505 &
                      nmp_wbid != 3202)

# replace wbid with NMP wbid
readiness$nmp_wbid <- as.character(readiness$nmp_wbid)
readiness$`Sampling Point` <- as.character(readiness$`Sampling Point`)
results_filtered <- left_join(results_filtered,
  readiness,
  by = join_by(
    location_id == `Sampling Point`
  )
)

results_filtered$wbid <- results_filtered$nmp_wbid

path <- paste0(
  "C:/Users/",
  user,
  "/OneDrive - Scottish Environment Protection Agency/DNA Data/Readiness Data/classification/classification-latest-published.xlsx"
)

class <- readxl::read_excel(path = path)

aspt_class <- filter(
  class,
  REPORTING_PARAMETER == "Macroinvertebrates (ASPT)" &
    ON_WATER_BODY == "Y"
)
aspt_class$parameter <- "Macroinvertebrates (ASPT) - Rivers"

ntaxa_class <- filter(
  class,
  REPORTING_PARAMETER == "Macroinvertebrates (NTAXA)" &
    ON_WATER_BODY == "Y"
)
ntaxa_class$parameter <- "Macroinvertebrates (NTAXA) - Rivers"

diatom_class <- filter(
  class,
  REPORTING_PARAMETER == "Phytobenthos (diatoms)" &
    ON_WATER_BODY == "Y"
)
diatom_class$parameter <- "Phytobenthos (diatoms) - Rivers"

previous_class <- bind_rows(aspt_class, ntaxa_class, diatom_class)

previous_class$WATER_BODY_ID <- as.character(previous_class$WATER_BODY_ID)
results_filtered <- left_join(results_filtered,
  previous_class,
  by = join_by(
    wbid == WATER_BODY_ID,
    parameter == parameter
  )
)

results_filtered$change <- results_filtered$Class == results_filtered$STATUS_DESCRIPTION
results_filtered$change[results_filtered$change == FALSE] <- "Y"
results_filtered$change[results_filtered$change == TRUE] <- "N"

test <- results_filtered[!is.na(results_filtered$change), ]

test$Class <- dplyr::recode_factor(test$Class,
  "High" = "High",
  "Good" = "Good",
  "Moderate" = "Moderate"
)
test$STATUS_DESCRIPTION <- dplyr::recode_factor(test$STATUS_DESCRIPTION,
  "High" = "High",
  "Good" = "Good",
  "Moderate" = "Moderate"
)
diatom_test <- test[test$parameter == "Phytobenthos (diatoms) - Rivers", ]
invert_test <- test[test$parameter == "Macroinvertebrates (ASPT) - Rivers", ]

table(diatom_test$Class, diatom_test$STATUS_DESCRIPTION)
table(invert_test$Class, invert_test$STATUS_DESCRIPTION)
```

# Check Years

2022 can include results from with data only from 2019. Only include locations with data from 2021 or 2022, 2023 or 2024.

```{r}
results_filtered$`Years included` <-
  gsub(",", "&", results_filtered$`Years included`)
results_filtered$check <-
  grepl("2021", results_filtered$`Years included`)

results_filtered$check[results_filtered$check == FALSE] <-
  grepl("2022", results_filtered$`Years included`[results_filtered$check == FALSE])

results_filtered$check[results_filtered$check == FALSE] <-
  grepl("2023", results_filtered$`Years included`[results_filtered$check == FALSE])

results_filtered$check[results_filtered$check == FALSE] <-
  grepl("2024", results_filtered$`Years included`[results_filtered$check == FALSE])


results_filtered <- results_filtered[results_filtered$check == TRUE, ]
```

# Select

```{r}
results_filtered <- results_filtered %>% select(
  "Parameter" = parameter,
  "WB ID" = wbid,
  "Location Code" = location_id,
  EQR,
  Class,
  CoCH,
  CoCG,
  CoCM,
  CoCP,
  CoCB,
  change,
  `Years included`,
  `Suit Code`,
  `Suit Text`,
  "Previous class" = STATUS_DESCRIPTION,
  mon_purp
)
```

Max CoC

```{r}
results_filtered$CoCH <- as.numeric(results_filtered$CoCH)
results_filtered$CoCG <- as.numeric(results_filtered$CoCG)
results_filtered$CoCM <- as.numeric(results_filtered$CoCM)
results_filtered$CoCP <- as.numeric(results_filtered$CoCP)
results_filtered$CoCB <- as.numeric(results_filtered$CoCB)

results_filtered$class_CoC <- pmax(
  results_filtered$CoCH,
  results_filtered$CoCG,
  results_filtered$CoCM,
  results_filtered$CoCP,
  results_filtered$CoCB
)


results_filtered <- unique(results_filtered)
```

# Reportable

What's reportable?

```{r}
# 2024
# Use replocs? If on replocs then use.

user <- Sys.info()["user"]
path <- paste0(
  "C:/Users/",
  user,
  "/OneDrive - Scottish Environment Protection Agency/DNA Data/Readiness Data/classification/replocs-live.csv"
)

replocs <- read.csv(path)

results_filtered$lookup[
  results_filtered$Parameter == "Macroinvertebrates (ASPT) - Rivers" |
    results_filtered$Parameter == "Macroinvertebrates (NTAXA) - Rivers"
] <- "Macro-invertebrates (WHPT)"

results_filtered$lookup[
  results_filtered$Parameter == "Phytobenthos (diatoms) - Rivers"
] <- "Phytobenthos (diatoms)"

replocs$LOCATION_CODE <- as.character(replocs$LOCATION_CODE)
replocs <- filter(replocs, CLASSIFICATION_PARAMETER %in% c("3688", "3968"))
replocs <- select(
  replocs,
  LOCATION_CODE,
  CLASSIFICATION_PARAMETER_DESC,
  ON_WB,
  WATER_BODY_ID
)


results_filtered <- left_join(results_filtered, replocs, by = join_by(
  lookup == CLASSIFICATION_PARAMETER_DESC,
  `Location Code` == LOCATION_CODE
))

results_filtered <- select(results_filtered, -lookup)

reportable <- results_filtered %>%
  filter(ON_WB == "Y")

diatoms_reportable <- reportable %>%
  filter(Parameter == "Phytobenthos (diatoms) - Rivers")

inverts_reportable <- reportable %>%
  filter(str_detect(Parameter, "invert"))

table(diatoms_reportable$Class, diatoms_reportable$`Previous class`)

table(inverts_reportable$Class, inverts_reportable$`Previous class`)
```

# Save data

```{r}
user <- Sys.info()["user"]
folder <- "/OneDrive - Scottish Environment Protection Agency/DNA Data/Readiness Data/classification/"
file_path <- paste0(
  "C:/Users/",
  user,
  folder
)

# Classification data final
class_path <- paste0(
  file_path,
  "2024-classification-final.csv"
)
write.csv(results_filtered,
  file = class_path,
  row.names = FALSE
)

# Classification diatom final
diatoms_path <- paste0(
  file_path,
  "2024-classification-diatoms-final.csv"
)
write.csv(diatoms_reportable,
  file = diatoms_path,
  row.names = FALSE
)

inverts_path <- paste0(
  file_path,
  "2024-classification-inverts-final.csv"
)

# Sample level classification
write.csv(inverts_reportable,
  file = inverts_path,
  row.names = FALSE
)

sample_info <- select(data, sample_id, date_taken, year) %>%
  distinct() %>%
  filter(year > 2016)
sample_test <- group_by(sample_info, sample_id) %>%
  mutate(n = n())
sample_info <- mutate(sample_info, sample_id = as.character(sample_id))
sample_info$sample_id <- as.character(sample_info$sample_id)
results$sample_id <- as.character(results$sample_id)
results_sample <- left_join(results,
  sample_info,
  by = join_by(sample_id), multiple = "first"
)
samples_path <- paste0(
  file_path,
  "sample-classification-2024.csv"
)
write.csv(results_sample, file = samples_path, row.names = FALSE)

# Alkalinity
alkalinity_path <- paste0(
  file_path,
  "alkalinity-2024.csv"
)
write.csv(alkalinity, file = alkalinity_path, row.names = FALSE)

# Raw data
raw_path <- paste0(
  file_path,
  "data-2024.csv"
)
write.csv(data, file = raw_path, row.names = FALSE)
```
