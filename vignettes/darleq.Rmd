---
title: "darleq"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{darleq}
  %\VignetteEncoding{UTF-8}  
  %\VignetteEngine{knitr::rmarkdown}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  echo = F
)
library(hera)
library(dplyr)
library(purrr)
library(tidyr)
library(tibble)
library(magrittr)
library(testthat)
library(rlang)
library(visNetwork)
```

<!-- Create a new regulatory assessment by changing the CAPITLIZE info below: -->

## Details

```{r setup}

standard <- tibble(
  standard_short = "darleq", # Short name for standard < 26 characters
  quality_element = "River Diatoms", # Quality element  < 26 characters
  parameter = "River Diatoms", # My parameter
  standard_long = "River Diatoms (phytobenthos)", # Optional - Long name for standard
  standard_reference = NA,
  aggregation = NA, # Optional - usually "waterbody" or "area"
  status = "testing" # Optional - "development", "on-hold", "consultation", "deprecated" or "deployed"
)

standard_format <- hera:::hera_format(standard = standard) # format assessment data
standard_format$standard %>%
  filter(attribute != "standard_reference") %>%
  knitr::kable()
```

## Data


```{r}

data <- read.csv(system.file("extdat/data-flow", "diatoms.csv", package = "hera"))

nodes <- data %>%
  select(-from, -to) %>% 
  unique() %>% 
  na.omit() %>% 
  mutate("id" = label) 
  
edges <- data %>%
  select(from, to) 


visNetwork(nodes, edges, width = "100%") %>%
  visEdges(arrows = "to") %>%
  visNodes(
    shadow = list(enabled = TRUE, size = 10),
    size = 50
  ) %>%
  visLegend() %>%
  visOptions(highlightNearest = list(enabled = T,
                                     degree = 2,
                                     hover = T)) %>%
  visHierarchicalLayout(direction = "UD", levelSeparation = 150) %>%
  visOptions(highlightNearest = list(enabled = T, hover = T), 
             nodesIdSelection = T)
  


```


```{r data}
all_data <- get_data(location_id = c(92751, 100))
all_data$year <- lubridate::year(all_data$date_taken)
data <- all_data
#  all_data <- all_data %>% filter(parameter == "River Diatoms")
# all_data <- filter(all_data , question == "percentagecoverband")


# attach(demo_data)
# demo_data$label <- demo_data$taxon
# demo_data$dist_from_source <- 32
# demo_data$alkalinity <- demo_data$mean_alkalinity
# demo_data$slope <- 2
# demo_data$source_altitude <- 280
# demo_data$parameter <- NA
# demo_data$parameter[demo_data$analysis_name == "MAC_R_TST"] <- "River Macrophytes"
# demo_data$parameter[demo_data$analysis_name == "DIAT_R_TST"] <- "River Diatoms"
# demo_data$sample_id <- as.character(demo_data$sample_id)
#
# all_data <- demo_data
# data <- demo_data %>%  filter(parameter == "River Diatoms")
# data <- data %>% filter(question == "Taxon abundance")
```

## Locate

Metadata required about the location

```{r locate}
# A list of metadata for location of sampling
location <- data %>% select(
  location_id,
  location_description,
  grid_reference
)
location <- location %>% unique()
head(location)
```

## Sample

Metadata required to assess each sample. (Excluding direct observations)

```{r sample}
# A list of questions and responses collected through observation
sample <- data %>% select(
  parameter,
  sample_id,
  date_taken
)
sample <- sample %>% unique()
head(sample)
```

## Observe

```{r}
questions <- data %>% filter(parameter == "River Diatoms")
questions <- questions %>% select(
  question,
  response,
  label, # optional (usually for taxonomic/species name)
  result_id,
  units
  )

questions <- questions %>% filter(question == "Taxon abundance")
questions
```

## Metrics

Trophic Diatom Index

```{r indices}

indices_function <- function(data) {
  if (!"label" %in% colnames(data)) {
    return(NULL)
  }
  if (all(is.na(data$label))) {
    return(NULL)
  }
  require(dplyr)
  require(tidyr)
  require(magrittr)
  require(tibble)
  data <- data %>% dplyr::filter(parameter == "River Diatoms")
  # Combine mean alkalinity with other site headers
  header <- data %>%
    mutate(
      "SampleID" = as.factor(.data$sample_id),
      "DATE_TAKEN" = as.Date(.data$date_taken, tz = "GB")
    ) %>%
    select(.data$SampleID,
      "SiteID" = .data$location_id,
      "SAMPLE_DATE" = .data$date_taken,
      "Alkalinity" = .data$alkalinity
    ) %>%
    unique()

  # Loch samples also require an Alkalinity 'type';
  # 'HA' - High Alkalninty etc
  # This will be ignored if running river classification
  header$lake_TYPE <- NA
  header$lake_TYPE[header$Alkalinity > 50] <- "HA"
  header$lake_TYPE[header$Alkalinity >= 10 &
    header$Alkalinity <= 50] <- "MA"
  header$lake_TYPE[header$Alkalinity < 10] <- "LA"

  header$SiteID <- as.character(header$SiteID)
  ## Important: Arrange to match order of 'diatom_data' data frame.
  header <- arrange(header, .data$SampleID)

  # 2. Prepare dataframe of 'diatom_data' -------------------------------
  # - Include columns for each diatom ID (from NEMS Dares table)
  # - Values are abundances.
  # - row.names are SAMPLE_NUMBER.

  # DARES table
  # - must use table from NEMS - this links TAXON to TAXONLD code
  dares_table <- darleq3::darleq3_taxa
  # Filter for taxon abundance only
  diatom_taxon_abundance <- data %>%
    filter(.data$question == "taxon abundance" | .data$question == "Taxon abundance")

  # Join to S_TAXON_DARES table using Taxon name.
  diatom_taxonname <- diatom_taxon_abundance %>%
    select(.data$sample_id, .data$label, .data$response, .data$date_taken) %>%
    inner_join(dares_table[, c("TaxonName", "TaxonId", "TaxonNameSEPA")],
      by = c("label" = "TaxonNameSEPA")
    )

  diatom_taxonname$response <- as.numeric(diatom_taxonname$response)
  # Sum value if duplicate taxon names entered within a single sample
  diatom_tidied <- diatom_taxonname %>%
    group_by(.data$sample_id, .data$TaxonId, .data$label, .data$date_taken) %>%
    summarise(value = sum(.data$response), .groups = "drop")
  # Arrange to keep in same order as 'taxon_names' data.frame
  diatom_tidied <- diatom_tidied %>%
    ungroup() %>%
    arrange(.data$label) %>%
    select(-.data$label)

  # DARLEQ3 requires Taxon IDs and Values pivoted into wide format
  diatom_data <- diatom_tidied %>% pivot_wider(
    names_from = .data$TaxonId,
    values_from = .data$value,
  )
  diatom_data[is.na(diatom_data)] <- 0

  # Arrange by sampled_date to match order of 'header' data frame.
  diatom_data <- arrange(diatom_data, .data$sample_id)
  # darleq3 requires row.names equal SAMPLE_NUMBER. Must convert
  # to be data.frame first (row.names deprecated on tibble).
  diatom_data <- data.frame(diatom_data, check.names = FALSE)
  row.names(diatom_data) <- diatom_data$sample_id
  diatom_data <- select(diatom_data, -.data$sample_id, -.data$date_taken)

  # 3. Prepare dataframe of 'taxon_names'  ------------------------------
  # include columns 'TaxonCode','TaxonName'
  taxon_names <- diatom_taxonname %>%
    select("TaxonCode" = .data$TaxonId, "TaxonName" = .data$TaxonName) %>%
    unique()

  taxon_names <- arrange(taxon_names, .data$TaxonName)

  # Combine dataframes into named list ------------------------
  header <- data.frame(header)
  output <- darleq3::calc_Metric(diatom_data, metric = "TDI4")
  output <- darleq3::calc_EQR(output, header, truncate_EQR = TRUE, verbose = TRUE)

  output$EQR <- output$EQR %>%
    mutate(across(everything(), as.character))
  output <- output$EQR %>%
    pivot_longer(c(-SAMPLE_DATE, -SiteID, -SampleID),
      names_to = "question",
      values_to = "response"
    )

  output$sample_id <- output$SampleID
  output <- output %>% select(sample_id, question, response)
  output$response <- as.character(output$response)

  output <- output %>% filter(question %in% c(
    "Total_count",
    "Percent_in_TDI4",
    "N_TDI4",
    "N2_TDI4",
    "Max_TDI4",
    "TDI4",
    "Motile",
    "OrganicTolerant",
    "Planktic",
    "Saline",
    "Comments"
  ))

  return(output)
}
indexes <- indices_function(data)
indexes
```

## Predictors

```{r predictors}
predictors <- data %>% select(
  alkalinity,
  location_id
)
knitr::kable(head(predictors))
```

## Predict

```{r prediction}
prediction_function <- function(data) {
  require(dplyr)
  require(tidyr)
  require(magrittr)
  require(tibble)
  data$response <- as.numeric(data$response)
  # Generates prediction based on predictors...
  if (any(names(data) %in% "alkalinity")) {
    data$alkalinity[is.na(data$alkalinity)] <- 75
  } else {
    data$alkalinity <- 75
  }
  data$alkalinity <- as.numeric(data$alkalinity)
  # Combine mean alkalinity with other site headers
  header <- data %>%
    mutate(
      "SampleID" = as.factor(.data$sample_id),
      "DATE_TAKEN" = as.Date(.data$date_taken, tz = "GB")
    ) %>%
    select(.data$SampleID,
      "SiteID" = .data$location_id,
      "SAMPLE_DATE" = .data$date_taken,
      "Alkalinity" = .data$alkalinity
    ) %>%
    unique()

  # Loch samples also require an Alkalinity 'type';
  # 'HA' - High Alkalninty etc
  # This will be ignored if running river classification
  header$lake_TYPE <- NA
  header$lake_TYPE[header$Alkalinity > 50] <- "HA"
  header$lake_TYPE[header$Alkalinity >= 10 &
    header$Alkalinity <= 50] <- "MA"
  header$lake_TYPE[header$Alkalinity < 10] <- "LA"

  header$SiteID <- as.character(header$SiteID)
  ## Important: Arrange to match order of 'diatom_data' data frame.
  header <- arrange(header, .data$SampleID)

  # 2. Prepare dataframe of 'diatom_data' -------------------------------
  # - Include columns for each diatom ID (from NEMS Dares table)
  # - responses are abundances.
  # - row.names are SAMPLE_NUMBER.

  # DARES table
  # - must use table from NEMS - this links TAXON to TAXONLD code
  dares_table <- darleq3::darleq3_taxa
  # Filter for taxon abundance only
  diatom_taxon_abundance <- data %>%
    filter(.data$question == "taxon abundance" |
      .data$question == "Taxon abundance")

  # Join to S_TAXON_DARES table using Taxon name.
  diatom_taxonname <- diatom_taxon_abundance %>%
    select(.data$sample_id, .data$label, .data$response, .data$date_taken) %>%
    inner_join(dares_table[, c("TaxonName", "TaxonId", "TaxonNameSEPA")],
      by = c("label" = "TaxonNameSEPA")
    )

  # Make sure numeric
  diatom_taxonname$response <- as.numeric(as.character(diatom_taxonname$response))

  # Sum response if duplicate taxon names entered within a single sample
  diatom_tidied <- diatom_taxonname %>%
    group_by(.data$sample_id, .data$TaxonId, .data$label, .data$date_taken) %>%
    summarise(response = sum(.data$response, na.rm = TRUE), .groups = "drop")
  # Arrange to keep in same order as 'taxon_names' data.frame
  diatom_tidied <- diatom_tidied %>%
    ungroup() %>%
    arrange(.data$label) %>%
    select(-.data$label)

  # DARLEQ3 requires Taxon IDs and responses pivoted into wide format
  diatom_data <- diatom_tidied %>% pivot_wider(
    names_from = .data$TaxonId,
    values_from = .data$response,
  )
  diatom_data[is.na(diatom_data)] <- 0

  # Arrange by sampled_date to match order of 'header' data frame.
  diatom_data <- arrange(diatom_data, .data$sample_id)
  # darleq3 requires row.names equal SAMPLE_NUMBER. Must convert
  # to be data.frame first (row.names deprecated on tibble).
  diatom_data <- data.frame(diatom_data, check.names = FALSE)
  row.names(diatom_data) <- diatom_data$sample_id
  diatom_data <- select(diatom_data, -.data$sample_id, -.data$date_taken)

  # 3. Prepare dataframe of 'taxon_names'  ------------------------------
  # include columns 'TaxonCode','TaxonName'
  taxon_names <- diatom_taxonname %>%
    select("TaxonCode" = .data$TaxonId, "TaxonName" = .data$TaxonName) %>%
    unique()

  taxon_names <- arrange(taxon_names, .data$TaxonName)

  # Combine dataframes into named list ------------------------
  header <- data.frame(header)
  header <- header[header$SampleID %in% row.names(diatom_data), ]
  header <- header[!duplicated(header$SampleID), ]
  output <- darleq3::calc_Metric(diatom_data, metric = "TDI4")
  output <- darleq3::calc_EQR(output, header, truncate_EQR = TRUE, verbose = TRUE)
  output <- tibble(
    "location_id" = output$EQR$SiteID,
    "question" = "eTDI4",
    "response" = output$EQR$eTDI4
  )
  return(output)
}


data$response <- as.character(data$response)
predictions <- prediction_function(data = data)
predictions
```


```{r together, echo=FALSE}

# All Together Now
sample_info <- data %>%
  select(names(sample), names(location)) %>%
  unique()

if (!is.null(indexes)) {
  indexes <- right_join(sample_info, indexes,
    by = c("sample_id" = "sample_id")
  )
} else {
  indexes <- data
}

predictions <- right_join(sample_info, predictions,
  by = c("location_id" = "location_id")
)
predictions$response <- as.character(predictions$response)

combined_data <- bind_rows(questions, predictions, indexes)
```

## Assessment

```{r assessment_table}

assessment_table <- tibble(
  assesssment = c("high", "good", "moderate", "poor", "bad"),
  value = c(0.80, 0.60, 0.40, 0.20, 0),
  level = c(1:5)
)

assessment_table

```

## Assess

```{r assessment}
assessment_function <- function(data, assessment_table) {
  if (nrow(data %>% filter(question == "TDI4")) == 0) {
    return(NULL)
  }
  require(dplyr)
  require(tidyr)
  require(magrittr)
  require(tibble)


  # Transform data -----------------------------------------------------------
  data <- data %>%
    select(.data$sample_id, .data$question, .data$response) %>%
    filter(.data$question %in% c("eTDI4", "TDI4"))
  data$response <- as.numeric(data$response)

  data <- data %>%
    distinct() %>%
    group_by(.data$sample_id) %>%
    pivot_wider(names_from = .data$question, values_from = .data$response) %>%
    ungroup()
  data[is.na(data)] <- 0

  data$eqr <- data$TDI4 / data$eTDI4
  data$eqr[data$eqr > 1] <- 1

  class <- cut(data$eqr, 
    breaks = c(1, assessment_table$value),
    labels = rev(assessment_table$assesssment),
    include.lowest = TRUE
  )

  assessments <- data.frame(
    sample_id = data$sample_id,
    class = as.character(class),
    eqr = as.character(data$eqr),
    status = "classified",
    level = "1"
  )

  assessments <- pivot_longer(assessments, -sample_id,
    names_to = "question", values_to = "response"
  )

  return(assessments)
}
assessments <- assessment_function(combined_data, assessment_table)
assessments
```


## Confidence

```{r}
confidence_function <- function(data, aggregates = "sample_id") {
  message("Calculating confidence...")
  if (!any(names(data) %in% "n_sample")) {
    data$n_sample <- 1
  }
  data <- data %>% filter(question == "eqr")
  data <- pivot_wider(data, names_from = "question", values_from = "response")
  data$eqr <- as.numeric(data$eqr)

  # Add confidence columns ---------------------------------------------------
  data <- data %>% mutate(
    se = NA,
    trsfd_mean = NA,
    trsfd_error = NA,
    norm_dist_1 = NA,
    norm_dist_2 = NA,
    norm_dist_3 = NA,
    norm_dist_4 = NA,
    bad = NA,
    poor = NA,
    moderate = NA,
    good = NA,
    high = NA
  )
  # SE value ------------------------------------------------------------------
  data$se <- (0.04 + -2.98 * data$eqr + 2.96 * data$eqr^0.95) / sqrt(data$n_sample)
  data$trsfd_mean <- log(data$eqr / (1 - data$eqr))
  data$trsfd_error <- (data$se) / (data$eqr * (1 - data$eqr))
  data$norm_dist_1 <- pnorm((-1.386 - data$trsfd_mean) / (data$trsfd_error))
  data$norm_dist_2 <- pnorm((-0.405 - data$trsfd_mean) / (data$trsfd_error))
  data$norm_dist_3 <- pnorm((0.405 - data$trsfd_mean) / (data$trsfd_error))
  data$norm_dist_4 <- pnorm((1.386 - data$trsfd_mean) / (data$trsfd_error))

  data$bad <- round((100 * data$norm_dist_1), 1)
  data$bad[data$eqr > 0.95] <- 0
  data$bad[data$eqr <= 0.056] <- 88.1

  data$poor <- round((100 * (data$norm_dist_2 - data$norm_dist_1)), 1)
  data$poor[data$eqr > 0.95] <- 0
  data$poor[data$eqr <= 0.056] <- 9.6

  data$moderate <- round((100 * (data$norm_dist_3 - data$norm_dist_2)), 1)
  data$moderate[data$eqr > 0.95] <- 0
  data$moderate[data$eqr <= 0.056] <- 2

  data$good <- round((100 * (data$norm_dist_4 - data$norm_dist_3)), 1)
  data$good[data$eqr > 0.95] <- 0
  data$good[data$eqr <= 0.056] <- 0.4

  data$high <- round((100 * (1 - data$norm_dist_4)), 1)
  data$high[data$eqr > 0.95] <- 100
  data$high[data$eqr <= 0.056] <- 0

  data <- data %>% select(all_of(aggregates), high, good, moderate, poor, bad)

  data <- pivot_longer(data,
    cols = (-all_of(aggregates)),
    names_to = "question",
    values_to = "response"
  )
  data$response <- as.character(data$response)
  return(data)
}


confidences <- confidence_function(data = assessments)
confidences

```

## Aggregate

Default aggregation used for routine assessment

```{r}

aggregate_function <- function(data) {
  return(data)
}
agrregation <- aggregate_function(data = assessments)
```

## Report

List of reports where this assessment is used

```{r}



```

## Checklist

```{r checklist}
check_list <- hera:::hera_test(standard = standard)
knitr::kable(check_list$standard_check)
```

## Update hera

```{r}

catalogue <- hera::catalogue

model <- tibble(
  analysis_name = standard$parameter,
  assessment = standard$standard_long,
  standard = list(standard),
  location = list(location[1, ]),
  sample = list(sample[1, ]),
  validation_function = NA,
  indices_function = list(indices_function),
  prediction_function = list(prediction_function),
  assessment_function = list(assessment_function),
  confidence_function = list(confidence_function),
  indices = list(indexes[indexes$sample_id == indexes$sample_id[1], ]),
  assessment_table = list(assessment_table),
  questions = list(questions[1, ]),
  predictors = list(predictors[1, ]),
  predictions = list(predictions[predictions$location_id == predictions$location_id[1], ])
)

catalogue <- catalogue[catalogue$assessment != standard$standard_long, ]

catalogue <- bind_rows(catalogue, model)
new_catalogue <- catalogue
usethis::use_data(catalogue, overwrite = TRUE)
```

## Launch app

```{r launch_app, echo=TRUE, eval=FALSE}

# No need to edit this code
launch_app(new_catalogue = catalogue, data = all_data)

```
