---
title: "Request for Comment: Shared Design Principles for Creating and Deploying Regulatory Methods"
date: "`r Sys.Date()`"
pkgdown:
  as_is: yes
output: 
  rmarkdown::html_vignette:
    number_sections: yes
    toc: yes
vignette: >
  %\VignetteIndexEntry{Request for Comment: Shared Design Principles for Creating and Deploying Regulatory Methods}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}  
editor_options: 
  chunk_output_type: console 
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(comment = "")
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message = FALSE)

library(tidyverse)
library(hera)
library(darleq3)
library(fcs2)
library(rict)
set.seed(42)

```

```{r results="asis", echo=FALSE}
# directly adding css to output html without ruining css style https://stackoverflow.com/questions/29291633/adding-custom-css-tags-to-an-rmarkdown-html-document
cat("
<style>
img {
border: 0px;
outline: 0 ;
}
</style>
")
```
WORK IN PROGRESS - Drafting

![](images/heraverse_logo_2.png){ width=50% }

WARNING: Blue sky thinking ahead

Keywords: collection, modelling, prediction, classification, forecast, scenario

> **TL:DR - To get a flavour of running multiple classification tools using a shared**
> **interface and data structures - check out the [hera demo website GUI]()**

# Summary

We propose regulatory tools share a common set of design principles, interfaces
and data structures.

Specifically, we propose an official collection of R packages designed to
provide collaborative workflow for building and using classification tools. In
turn, these packages will be integrated into a single package called 'hera'.
This provides a common interface to run regulatory classification. We expect
this process will facilitate code re-use, faster integration and knowledge
exchange between method developers and practitioners.

# Motivation

UKTAG has guided the development of an impressive range of classification tools.
This has involved many developers, researchers and experts dedicating their time
and effort to creating tools to better understand pressures on the environment.
We are confident that there are many future opportunities for collaboration and
tool development in response to changing environmental pressures and improving
scientific understanding. As access to modelling tools become more routine, we
expect a proliferation of models and indices in the years ahead. For instance,
new tools for diagnosing pressures, updates to existing tools and catchment
scale planning. To aid better understanding of the environment through
effectively combining multiple models and tools, we propose a they share a
common design philosophy to aid integration and collaboration.

# Key Ideas

The aims of a shared design philosophy for regulatory classification R packages include:
  
- Create a single user interfaces, similar data formats and operating procedures.
- Allow outputs from multiple tools to be quickly generated and combined together.
- Shorten the time between development and integration into Agencies systems.
- Clearer path for researcher engagement and model development.
- Make it easier to share and re-use code between tools for common functions.
- Share data quality standards and data validation code. 
- Apply similar approaches to code review, testing and documentation.

## Preparing for future

In the next 10 years...
  
We assume it is likely that our aquatic ecological models will be subsumed into
a more large scale environmental and climate models. These 'total environment'
models may for instance use climate change models to forecast impact on
invertebrates, water-use models to predict the impact on fish or spatial
planning tools the impact on nutrient levels. The outputs will be used across
regulatory reporting for RBMP, flood management, biodiversity improvements,
carbon sequestering etc. Allowing multi-discipline assessment of impacts and
trade-offs for each planning scenario and proposed measures - ensuring
well-informed decisions-making.

All ecological data along with chemistry, climate, meteorological, geological
will be freely and easily accessible. We assume agencies will upload all data
such as fish counter data, plant DNA or aerial imagery etc, into a 'lake' of
environmental data.

To take step towards this vision, the underlying design of a models and tools
must be modular and easy to connect and integrate in a variety of ways.

# Detailed design

To aid collaboration and to response to the changing environmentally pressures,
we propose creating a joint collections of packages to share understanding on the
environment while providing the software infrastructure to lighten the burden of
more mundane tasks involved in maintaining and deploying new models and
interfaces. 

This is influenced by the work of climate change research and weather
forecasting communities. And on-going work in the R community such as [ropenSci](https://ropensci.org/).

## Shared Packages

Currently we have a number of classification tool R packages shared on github:
  
1. [darleq3](https://github.com/nsj3/darleq3) - Phytobenthos  
2. [fsc2](https://github.com/aquaMetrics/fcs2) - Scottish river fish  
3. [rict](https://github.com/aquaMetrics/rict) - General invertebrate classification  
  
We propose these tools become part of official collection of packages and
we work towards making them inter-operable via the `hera` package.

## Key steps

Here we introduce a prototype R package called
[hera](https://github.com/ecodata1/hera). The key idea, is `hera` provides a
common interface for existing WFD packages and future developments. This is
achieved through a set of shared functions required to run and report
classification. It builds on the best practice idea of how to [run many
models](https://r4ds.had.co.nz/many-models.html) simultaneously in R while
keeping the input and output data formats simple and homogeneous. We explain
each function in detail below. In summary, each step represents a function
within the hera package. This allows the re-use code and rules between existing
and future tool development.

**Steps**

1. Validation
2. Indices/metrics
3. Classification
4. Aggregation
5. Reporting
6. Diagnosis
7. Scenarios
  
The examples below provide a taste of how this RFC could be implemented. 
**Keep in mind, they are not full, complete or accurate. The data structure, naming and details could all change, they are presented as a rough draft**

### Validation

Firstly, sense-check the predictor and observation data is with expect limits.
Additionally, check the data is within the expect parameter space based on
training data used to create the classification model. Return the passing
data and list of warnings/fails.

```{r, echo=TRUE}
# install.packages("devtools")
# devtools::install_github("ecodata1/hera")
library(hera)
library(tidyverse)
demo_data <- hera::demo_data
validation(demo_data) %>% 
  head(5)
```

### Indices

Using the  `indices()` function, we calculate observed indices scores as required for each sample. 

```{r, echo=TRUE}
indices(demo_data) %>%
  select(sample_number, indices) %>%
  unnest(indices) %>% 
  group_by(quality_elements) %>%
  slice_sample(n = 4) 

```

Note, the invert indices are not calculated, they have been pre-calculated and are in the demo_data from the start. 

### Prediction 

We then predict reference scores for each sample:

```{r, echo=TRUE}
prediction(demo_data[1:2200, ]) %>%
  group_by(quality_elements) %>%
  slice_sample(n = 4) %>%
  select(sample_number, prediction) %>%
  unnest(prediction)

```

See documentation [`prediction()`](https://ecodata1.github.io/hera/reference/prediction.html)
for more information.

### Classification

Based on the predicted and observed indices - we classify each sample using `classification()`:

```{r, echo=TRUE}

classification(demo_data) %>% 
 group_by(quality_elements) %>% 
 slice_sample(n = 4) %>% 
 select(sample_number, classification)

```

Note, classification results for inverts are missing - this has not be implemented yet.

### Aggegation

We now aggregate the samples by season, year or multi-year as required:

```

aggregate <- aggregation(demo_data, c("year","season","waterbody"))
head(class)

```

### Report

We now run a report assessing samples from the same location for consistency.
Note, that no report for fish is produced, the necessary adjustment/interpretation
parameters have not been created for fish. This demonstrates that it is step by
step process. Not all tools/models will have all the features development if not
required or if not prioritized:

```
compare_report <- compare(new_data, old_data)
compare_report

```

We now run a report assesses two samples assess a discharge (up and downstream):  

```
compare_report <- compare(site_one, site_two)
compare_report

```

### Diagnosis

As well as classification of water quality, additional we need to diagnose potential pressures. We use the `diagnosis()` function to report potential pressures.

```
diagnosis(demo_data) %>% 
select(sample_id, diagnosis)
head()

```

### Scenarios

A number of forecasting or scenario tools could be incorporated for either projecting current trends or assessing the impact of proposed measures. 

```
scenario(demo_data, trends) %>%  
head()

scenario(demo_data, measures) %>% 
head()

```

### The Whole Game

For the most part we don't expect users to go through each of these steps. But
for developers and researchers it is useful to think about classification within
this framework. For the majority of end users, agency staff or consultants, they
can open the GUI `hera_app()` or visit the website directly. However, advanced
users can use the `hera` function to wrap all these steps together fot example
`hera(hera::demo_data)`.
  
Furthermore, agencies can integrate these functions into their systems using web
services. Please see the [demo web
service](https://cloud.opencpu.org/ocpu/apps/ecodata1/hera/info) and [api
documentation](https://www.opencpu.org/api.html) for using
[opencpu](https://www.opencpu.org/) hosted packages.

## Lots of datasets - one underlying data structure?

Ecological modelling relies on sampling. The samples come in a range of forms
from points, transects, images, grabs, DNA etc. But the general feature of
modelling is based on being able to predict what we expect to find from whatever
sampling technique we deploy. The sample is the fundamental observation which we
compare against our prediction. The samples are discreet, either observed
instantaneously or perhaps over a few minutes or hours (where dynamic changes
are not significant).
  
Multiple samples can be aggregated to smooth variance but the sample still
remains the fundamental building block. The sample could be a single pixel from
an aerial image or a salmon moving through a fish counter. We still make
predictions of what we expect this sample to be like even if the true picture
only emerges after several samples are aggregated or compared.

Therefore, all our data share similarities, they consist of samples and
observations. And additionally for each sample with have predictor variables to
allow us to predict expected reference condition values.

### Data dictionary

The Europe Environment Agency as produced a data dictionary for reporting. However this is mainly for high-level reporting. In particular, taxonomic results are not exchanged using this data strucuture. However, we use some aspects of this standard here to aid onward reporting to EEA.

### What does this look like?

A small sample demo dataset `demo_data` contains diatoms, macrophytes and inverts quality elements. 

```{r}
hera::demo_data %>%  
  select(location_description, date_taken, sample_id, quality_element) %>% 
  group_by(quality_element) %>% 
  slice_sample() %>% 
  head(5)
  
```

### Book-keeping variables

First of all, we have 'book-keeping' variables. These allow us to reference data
associated with particular samples, locations or WFD methods. And allow results
to be aggregate at different levels.

```{r}
hera::demo_data %>% select(location_id, sample_id, quality_element) %>% 
  head(5)

```

All data passed into hera must have these three variables. For *ad hoc*
reporting, consultancies and students etc who don't routinely record unique
sample ids, a sample_id is generate if `date_taken` and `location_id` are
provided.
  
These three variables are the minimal required, but in practice `water_body_id`
maybe required for aggregation or simply `location_description` or `NGR` etc to
help reference sites more easily. There is no restriction no what extra columns
are added and these columns will be added to the outputs.

### Observations

An observation consists of three variables `question`, `response`. The
`question` variable identifies what is being determined such as `alkalinity`
or `depth` etc. And the `response` is the value observed or recorded for that
question.

Below is an example of diatom records, invert data and river flow in a shared
input format.

```{r}
demo_data %>% select(question, response)

```
  
In theory, this is all that is required. However for ease for interacting with
existing dataset and *ad hoc* data, a fourth column `taxon` is useful due to the
historic way taxon data is usually stored.

```{r}
demo_data %>% select(question, response, taxon) %>% 
  slice_sample(n = 5)

```

### Predictors

Predictive variables such as `temperature`, `altitude`, `slope` are added as
additional columns. There is a trade-off here as predictor variables are added
for each row in the dataset, increasing the size of the dataset. However this
does make data analysis straightforward and this repeated can be easily
compressed if size becomes an issue.

```
demo_data %>%  select(`mean_alkalinity`, `altitude`, `distance_from_source`)

```

### Indices, predictions, classification, reports

The outputs are all presented in a consistent format making
outputs from different models instantly comparable and portable.

## Data input

For students and consultancies requiring *ad hoc* usage, templates and documentation for preparing data will be provided. 

For Agencies, data queries can be written to prepare outputs in the correct format. 

For instance, we imagine each agency will have an R package to pull data from their databases and convert to the required input format

```
tay_data <- import_data(river_name = "River Tay")
hera(tay_data)

```

## Shared Data Tables 

Following data tables are shared through `hera`...

* Validation Rules
* Indices, Model and Environmental Standards
* Taxon Table
* EQR Boundaries
* Parameter Hierarchy

### Models and Environmental Standards names

```{r}

hera:::create_model_dataframe() %>% 
  select(standard, quality_element, classification_function)


```



## Model platform

This RFC is mainly looking at a share design for inputs and outputs from
classification tools.

This framework does however encourage a shared principles in thinking about the
approach to modelling required which drives the classification method. However,
we see no need to prescribe a modelling program or software. Researchers can
download the reference and predictor data required and use any software they
desire. Ultimately, the model we need to be called by R. So either the model
needs to be written into R or in language which can be called by R (Python,
fortran, C++ etc).

Alternatively, if researchers can't provide an api for R to call, the
recommendation is to use R - which integrates more directly into the pipeline.

Once modelling is completed, the model object is saved and deployed. Any
existing or future data collected using the platform will be run through the
model at the sample level.
  
Researchers can then build tools to display and aggregate the sample level
results as required (Waterbody, Year, Catchment etc). Where it would be possible
to share techniques for producing Confidence of Class, assessment of data
suitability and adjustment factors etc.

# How we Teach This

As new regulatory developments and updates requirements are identified, the lead
contacts from the agencies and method developers are 'on-boarded' to demonstrate
the design principles and collaborative framework of packages. Where skill
development is required further training can be provided, or additional external
or internal support from the agency commissioning the work.
  
A workshop for lead data experts / R coders from each agency delivers
institutional knowledge on how internally developed tools will fit with the
shared design philosophy as well as seeting expectations for colloaboration with
external researchers.

## Sharing

Hera allows multiple ecological elements to be assessed through the same
interface. But not just the interface is shared. Other areas of the
infrastructure are shared including:

- Reporting and comparison tools can also be shared between multiple
elements. 
- Validation checks and other universally required mechanisms
are shared and easily configurable for new models/methods.
- Testing infrastructure. 
- Confidence of class and data suitability algorithms. 

## Organisation

All UKTAG sub-groups and their nominated leads in the devolved agencies would
contribute new method develops and tools to the shared collection of packages.
Where tools are agency specific, these could also make use of the platform if
required.

As agencies commission new tools to be developed, researchers can upload their
predictive variables, reference data and models into a central repo for easier
collaboration.


# Alternatives



# Unresolved questions

- Should all reference/predictor data be combined into a single repository / web service?

# Appendix


## List of current data structure in R packages

### FCS2 tool 

Demo input data format (truncated) and full list of column names
```{r}
 test <- head(fcs2::demo_data)
test <-  test[1:4, 1:6]
test$... <- "..."
test
 names(fcs2::demo_data)
```

Ouput

```{r, include=FALSE}
results <- calcClassScot(data = fcs2::demo_data)
```

```{r}
test <- results[1:4, 1:6]
test$... <- "..."
test
names(results)
```


### Darleq tool

Input data for DARLEQ3 tool is a list of dataframes. Here's an example of input
data format (truncated) and full list of column names

```{r}

file <- system.file("extdata/DARLEQ2TestData.xlsx", package="darleq3")
data <- read_DARLEQ(file, "Rivers TDI Test Data")
test <- data$diatom_data[1:4, 1:8]
test$... <- "..."
test
names(data$diatom_data)
names(data$header)
```

Output
(list of dataframes)

```{r}
fn <- system.file("extdata/DARLEQ2TestData.xlsx", package="darleq3")
d <- read_DARLEQ(fn, "Rivers TDI Test Data")
results <- calc_Metric_EQR(d, metrics=c("TDI4", "TDI5LM"))
head(results$TDI5LM$EQR[, 9:13])
head(results$TDI5LM$Uncertainty[, 9:13])
head(results$TDI5LM$Metric)
head(results$TDI5LM$Job_Summary, 4)
```


### RICT

Here's an example of input data format (truncated) and full list of column names

```{r}
test <- rict::demo_observed_values[1:4, 1:8]
test$... <- "..."
test
names(demo_observed_values)
```

Output

```{r, warning=F, message=F}
test <- rict(demo_ni_observed_values)
example <- head(test[1: 6], 4)
example$... <- "..."
example
names(test)
```


