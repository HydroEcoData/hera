---
title: "assessment-checking"
format: html
editor: visual
editor_options: 
  chunk_output_type: console
---

# TODO

-   Grab all the data ✓
-   Compare changes in real classification between years?
-   Difficult because sites not always sampled every year.
-   Need a solution.
-   Compare to changes between new tools and old for single year(s)?
-   95% changes in diatom classification? Needs more checking - possibility alkalinity 75 override issues?
-   Check rict using year average predictors
-   Tested sample_id = 2755381, slight difference in EQR. Maybe due to difference in Akalinity?
-   Use tests from sepaData package
-   Need to use mean_alkalinity( n = 10) to get previously used Alkalinity ✓
-   Check one site against RICT3 output?
-   Need solution for finding water body IDs for location for invert sites. No contributing location? - Use NMP spreadsheet?
-   Check results from darleq2 outputs against NEMS? Run sample through DARLEQ3 and hera?
-   Have a look at suitability codes
-   Have a look at warnings and fails?
-   Have a look at excluded samples (missing Alk for Diatoms etc)
-   Use dynamic predictive variables
-   Test one sample from beginning to end??
-   Test 8175 first? Using unit tests? OKAY! ✓
-   Unit test for mean_alkalinity
-   Unit test for RICT
-   Unit test for DARLEQ
-   Get all alkalinity from lims ✓
-   Get alkalinity from recovered data - all data? ✓
-   Join lims + recovered alk - 'hera' format? ✓
-   Update sampling point table
-   Join chemistry with Ecology data ✓
-   Query alkalinity data using alt_site - get mean_alkalinty ✓
-   Check missing grid_reference from recovered data? Join location table?
-   Add suitability code
-   Classify
-   Join with 2020 classification?
-   Sewage fungus override - manual check?
-   Missing NGR in recovered data?
-   Convert() function does a lot of tweaks - can these go in a .csv lookup file?

```{r}
library(hera)
library(tidyverse)
library(arrow)
```

# Test Locations

Only surveillance sites for speed of testing.

```{r}
# locs <- read.csv("vignettes//data//invert-surv-locs-subset.csv")
```

# LIMS Data

Open files of pre-fetched data from LIMS. Data was downloaded from LIMS using 'RESULTS' query. Additionally, test \> test number and sample \> collection date (DUE DATE) columns were added for data processing reasons.

## Ecology

```{r}

 lims_eco <- readr::read_csv(
  "vignettes//data//2024-03-18-lims-data.csv"
 )
#test_lims <- lims_eco[lims_eco$SAMPLING_POINT == "3798", ]
# test_eco <- readr::read_csv(
#   "vignettes//data//2023-04-02-lims-data.csv"
# )
#
# unique(test_eco$SAMPLING_POINT[!test_eco$SAMPLING_POINT %in% lims_eco$location_id])
```

Use collection date if sampled date not present

```{r}
# lims_eco$SAMPLED_DATE[is.na(lims_eco$SAMPLED_DATE)] <-
#  lims_eco$DUE_DATE[is.na(lims_eco$SAMPLED_DATE)]

# Need to rename columns from LIMS extract to match expected names for the convert() function below
lims_eco$REPORTED_NAME <-  lims_eco$DETERMINAND_NAME
lims_eco$FORMATTED_ENTRY <-  lims_eco$RESULT
lims_eco$DESCRIPTION <- lims_eco$SAMPLING_POINT_DESCRIPTION
lims_eco$SAMPLE_NUMBER <- lims_eco$ORIGINAL_SAMPLE
```

Convert LIMS data into standard data format for hera package so metrics etc can be calculated.

```{r}
lims_eco <- hera::convert(lims_eco,
  convert_to = "hera",
  convert_from = "sepa_lims"
)

# test_lims <- lims_eco[lims_eco$location_id == "10116", ]
```

## Chemistry

```{r}
# lims_chem <- readr::read_csv(
#   "vignettes//data//chem-lims-data.csv"
# )

# Need a test number for convert() function but not used for chemistry so dummy
# test number added.
# lims_chem$TEST_NUMBER <- 1
# lims_chem <- hera::convert(lims_chem,
#   convert_to = "hera",
#   convert_from = "sepa_lims"
# )
```

## Merge

```{r}
#lims_data <- bind_rows(lims_eco, lims_chem)
lims_data <- lims_eco
```

# Recovered data

## Query

Get Ecology analytical results based on LIMS locations. WARNING this takes 1hr + to run! Better to filter to a few specific locations.

```{r, eval=FALSE}
# recovered_data <- get_data(location_id = unique(lims_eco$location_id))

# chem_test <- get_data(7856, dataset = "chem_analytical_results")
# recovered_data  <- get_data(location_id = c("398593",   "8207"))
# 
# recovered_data$parameter[is.na(recovered_data$parameter)] <-
#   recovered_data$analysis_repname[is.na(recovered_data$parameter)]
# 
# recovered_data <- dplyr::filter(recovered_data, parameter %in% c(
#   "River Family Inverts",
#   "River Diatoms",
#   "Invert Physical Data"
# ))
# 
# write.csv(recovered_data, file = "vignettes//data//2023-04-04-data.csv")
```

## Pre-fetched data

```{r}
# Recovered data  ----------------------
# eco_data <- readr::read_csv(
#   "vignettes//data//2023-04-04-data.csv"
# )
# 
# new_eco_data <- readr::read_csv(
#   "vignettes//data//2023-04-14-data.csv"
# )

# eco_data <- bind_rows(eco_data, new_eco_data)

ds <- open_dataset("C:/Users/Tim.Foster/Documents/r-projects/data/all_data_clean_public.arrow", format =  "arrow")

eco_data <-  ds %>%
  filter(parameter %in% c("River Family Inverts",
  "River Diatoms",
  "SURVEY_INV"))  %>%
  collect()


eco_data <- unique(eco_data)

eco_data$parameter[is.na(eco_data$parameter)] <- eco_data$analysis_repname[is.na(eco_data$parameter)]

eco_data <- dplyr::filter(eco_data, parameter %in% c(
  "River Family Inverts",
  "River Diatoms",
  "SURVEY_INV"
))

eco_data$parameter[eco_data$parameter == "SURVEY_INV"] <- "River Family Inverts"

eco_data$question[eco_data$question ==
  "% Boulders/Cobbles"] <- "boulders_cobbles"
eco_data$question[eco_data$question ==
  "% Pebbles/Gravel"] <- "pebbles_gravel"
eco_data$question[eco_data$question ==
  "% Sand"] <- "sand"
eco_data$question[eco_data$question ==
  "% Silt/Clay"] <- "silt_clay"
eco_data$question[eco_data$question ==
  "River Width (m)"] <- "river_width"
eco_data$question[eco_data$question ==
  "Mean Depth (cm)"] <- "mean_depth"

# alk_predictor_sites <- hera::get_data(predictors$chemistry_site, dataset = "chem_analytical_results")

# Get all chem alk data pre sept 2019
alk_results_sep_19 <- readxl::read_excel("vignettes/data/ALK_RESULTS_CHEM_SEP19.xlsx")

alk_results_sep_19$DATE_TAKEN <- substr(alk_results_sep_19$DATE_TAKEN, 1,10)
alk_results_sep_19$DATE_TAKEN <- as.Date(alk_results_sep_19$DATE_TAKEN)

names(alk_results_sep_19) <- tolower(names(alk_results_sep_19))
alk_results_sep_19 <- select(alk_results_sep_19,
location_code,
media,
date_taken,
sample_no,
test_number,
purpose,
wfd_purpose,
determinand_code,
determinand,
result,
units_code,
sign,
loq_result,
loq_sign
)


alk_data <- hera::convert(alk_results_sep_19, convert_from = "sepa_chem", convert_to = "hera")

# alk_data <- readr::read_csv(
#   "vignettes//data//alk-data.csv"
# )

eco_data$date_taken <- as.Date(eco_data$date_taken)
# eco_data$determinand_code <- as.character(eco_data$determinand_code)
eco_data$test_number <- as.character(eco_data$test_number)
eco_data$location_id <- as.character(eco_data$location_id)
eco_data$sample_id <- as.character(eco_data$sample_id)

alk_data$units <- as.character(alk_data$units)
alk_data$response <- as.character(alk_data$response)
alk_data$test_number <- as.character(alk_data$test_number)
alk_data$location_id <- as.character(alk_data$location_id)
alk_data$sample_id <- as.character(alk_data$sample_id)

recovered_data <- bind_rows(eco_data, alk_data)
```

# Combine Data

```{r}
data <- bind_rows(recovered_data, lims_data)
data$parameter[is.na(data$parameter)] <- "PAC"

recovered_data <- NULL
eco_data <- NULL
lims_chem <- NULL
lims_data <- NULL
lims_eco <- NULL
alk_data <- NULL
```

# Filter

Only core surveillance sites to speed up testing and filter out ecology old samples.

```{r}
#  data <- data[data$location_id %in% unique(locs$Loc), ]
data$year <- lubridate::year(data$date_taken)
data <- data %>% filter(year >= 2016 | parameter == "PAC")
```

# NMP

Get the NMP spreadsheets, to get the waterbody_id. This is needed to link results to previous classification outputs??...not sure - needs to be location based classification?

# Predictors

Get RICT predictors.

```{r, message=FALSE}
# Filter data-----------------------------------------------------------------
# We only want samples that pass our criteria (season, number of samples etc)
# data <- filter(data, parameter %in% c("River Family Inverts",
#                                       "River Diatoms"))

predictors <- utils::read.csv(
  system.file("extdat",
    "predictors.csv",
    package = "hera"
  ),
  stringsAsFactors = FALSE, check.names = FALSE
)
predictors$location_id <- as.character(predictors$location_id)

# use latest 'version' for each location_id
predictors <- arrange(predictors, desc(date))
predictors <- select(
  predictors,
  alkalinity,
  location_id,
  grid_reference,
  chemistry_site,
  altitude,
  slope,
  discharge_category,
  dist_from_source
)
predictors <- predictors[!duplicated(predictors$location_id), ]

data <- left_join(data, predictors, by = c("location_id"))
predictors <- NULL
```

# Calculate Alkalinity

If alkalinity required calculate.

```{r, eval=FALSE}
data$alkalinity <- NULL
Sys.time()
alkalinity <- hera:::mean_alkalinity(data)
Sys.time()
data <- inner_join(data,
  alkalinity,
  by = join_by("sample_id" == "sample_number")
)
#test_data <- data[data$location_id == "3798",]
#test_data <- data[data$location_id == "10116", ]
eco_missing_alk <- data$sample_id[data$question == "pebbles_gravel" &
  is.na(data$alkalinity)]
data <- data[!data$sample_id %in% eco_missing_alk, ]
eco_missing_alk2 <- data$sample_id[data$question == "Taxon name" &
  is.na(data$alkalinity)]
data <- data[!data$sample_id %in% eco_missing_alk2, ]
#test_data <- data[data$location_id == "10116", ]
```

# Classification 2023

RUn 2023 classification

## Classify

```{r, message=FALSE}
 write.csv(data,"vignettes//data//2024-03-13-data.csv", row.names = FALSE)
data <- read.csv("vignettes//data//2024-03-18-data.csv")
data <- data[!is.na(data$grid_reference), ]
data <- data[data$grid_reference != "", ]
# data <- data[data$location_id != "4359",]
# 
# invert_data <- data[data$parameter == "River Family Inverts",]
# data <- data[data$parameter != "River Family Inverts",] 
# invert_data <- group_by(invert_data, sample_id, analysis_repname) %>% 
#   summarise(count = n())


# Re-run 4359 - data only entered in July 2023!
# Needs special treatment (results copied and pasted into final classification outputs)
# data <- data[data$location_id == "4359",]
# Filter out pre-2019 data because river has recently suffered mine water impact - and want full impact of mine water to be reflected in classification
# data <- data[year(data$date_taken) > 2019, ]

# Issue with NGR out of temp grid
# test_data <- data[data$location_id == "488482",]
# test_data <- data[data$location_id == "529",]
# test_data <- data[data$location_id == "10116",]
# test_data <- data[data$location_id == "9542",]
# data <- data[data$location_id != "320",]
# data <- data[data$location_id != "100690",]
# data <- data[data$parameter == "River Diatoms", ]

data <- mutate(data, year = lubridate::year(date_taken))
 data <- dplyr::group_by(data, location_id, parameter) %>%
        dplyr::mutate(max_year = max(year))
 data <- ungroup(data)

 # invert_data <- data[data$parameter == "River Family Inverts", ]
 # invert_data <- select(invert_data, 
 #                        parameter, 
 #                        analysis_repname,
 #                        location_id) %>% distinct()
 # write.csv(invert_data, "vignettes//data//invert_data-2024-03-13.csv")
 # test <- data %>% filter(location_id == 10116)
 
results <- map_df(c(2021,2022,2023), function(class_year) {

  ids <- unique(data[data$max_year == class_year, c("sample_id", "parameter")])
  filter_data <- inner_join(data,
                            ids, by = join_by(sample_id, parameter))
  #filter_data <- data[data$sample_id %in% ids, ]
  # filter_data <- filter_data[filter_data$location_id == "3798",]
  filtered_data <- filter_data %>%
    filter(year <= class_year) %>%
    hera:::filter_samples(classification_year_data = TRUE)
    

  wfd_results <- map_df(split(filtered_data, filtered_data$location_id), function(location) {
    wfd_result <- assess(location,
      name = c("RICT", "DARLEQ3")
    )

  }, .progress = TRUE)
})
```

# Filter

```{r, message=FALSE}
# Filter out the predicted values and sample level results. We only want the
# location level results
results <- results[!is.na(results$location_id), ]


results_filtered <- filter(
  results,
  question %in% c(
    "CoCH",
    "CoCG",
    "CoCM",
    "CoCP",
    "CoCB",
    "Class",
    "EQR",
    "Years included",
    "Comments",
    "Suit Code",
    "Suit Text"
  ),
  is.na(sample_id)
) %>%
  select(-sample_id)

# Pivot results to make them look nice
results_filtered <- pivot_wider(results_filtered,
  names_from = question,
  values_from = response
)


results_filtered <- results_filtered %>%
  mutate(
    parameter = ifelse(parameter == "Macroinvertebrates (ASPT)",
      "Macroinvertebrates (ASPT) - Rivers",
      parameter
    ),
    parameter = ifelse(parameter == "Macroinvertebrates (NTAXA)",
      "Macroinvertebrates (NTAXA) - Rivers",
      parameter
    ),
    parameter = ifelse(parameter == "Phytobenthos (diatoms)",
      "Phytobenthos (diatoms) - Rivers",
      parameter
    )
  )
```

# NMP

Add NMP to get WBIDs?

```{r}
nmp_diatoms <- readxl::read_xlsx(
  path =
    "vignettes//data//nmp-diatoms-draft-2023.xlsx"
)
nmp_diatoms$analysis <- "DIATOMS"

nmp_inverts <- readxl::read_xlsx(
  path =
    "vignettes//data//nmp-inverts-draft-2023.xlsx"
)
nmp_inverts$analysis <- "INVERTS"
nmp <- bind_rows(nmp_diatoms, nmp_inverts)
```

# Join NMP

```{r}
nmp <- select(nmp,
  "location_id" = Loc,
  "wbid" = WBID,
  analysis,
  "replocs_check" = `CHK REPLOCS`,
  "mon_purp" = `REG Mon Reason`
)

diatoms <- nmp[nmp$analysis == "DIATOMS", ]
diatoms$analysis <- "Phytobenthos (diatoms) - Rivers"
inverts <- nmp[nmp$analysis == "INVERTS", ]
aspt <- inverts
ntaxa <- inverts
aspt$analysis <- "Macroinvertebrates (ASPT) - Rivers"
ntaxa$analysis <- "Macroinvertebrates (NTAXA) - Rivers"
all_nmp <- bind_rows(aspt, ntaxa, diatoms)
all_nmp$location_id <- as.character(all_nmp$location_id)
all_nmp$wbid <- as.character(all_nmp$wbid)
results_filtered <- left_join(results_filtered, all_nmp, by = join_by(
  location_id,
  parameter == analysis
))
```

# Previous Class

Join 2020 classification results based on WB

```{r}
aspt_class <- readxl::read_excel(
  path =
    "vignettes//data//aspt-classification-2022.xlsx"
)
aspt_class$parameter <- "Macroinvertebrates (ASPT) - Rivers"

ntaxa_class <- readxl::read_excel(
  path =
    "vignettes/data//ntaxa-classification-2022.xlsx"
)
ntaxa_class$parameter <- "Macroinvertebrates (NTAXA) - Rivers"

diatom_class <- readxl::read_excel(
  path =
    "vignettes//data//diatom-classification-2022.xlsx"
)
diatom_class$parameter <- "Phytobenthos (diatoms) - Rivers"

previous_class <- bind_rows(aspt_class, ntaxa_class, diatom_class)

previous_class$ID <- as.character(previous_class$ID)
results_filtered <- left_join(results_filtered, previous_class, by = join_by(wbid == ID, parameter == parameter))

# aspt_ntaxa_2022 <- 
#   read.csv("vignettes/data//aspt-ntaxa-classification-2022.csv")
# diatoms_2022 <-
# read.csv("vignettes/data//diatoms-classification-2022.csv")
# #"WBID"      "WB_NAME"   "CONDITION" "parameter"
# class_2022 <- bind_rows(aspt_ntaxa_2022, diatoms_2022)
# 
# class_2022$WB.ID <- as.character(class_2022$WB.ID)
# class_2022 <- select(class_2022, WB.ID, "parameter" =Parameter, "CONDITION" = Class)
# results_filtered <- left_join(results_filtered, class_2022, by = join_by(wbid == WB.ID, parameter == parameter))
# results_filtered$`2022 Class`[is.na(results_filtered$`2022 Class`)] <- "No"
# results_filtered$`2022 Class`[results_filtered$`2022 Class` != "No"] <- "Yes"



results_filtered$change <- results_filtered$Class == results_filtered$Condition
results_filtered$change[results_filtered$change == FALSE] <- "Y"
results_filtered$change[results_filtered$change == TRUE] <- "N"

test <- results_filtered[!is.na(results_filtered$change), ]

test$Class <- dplyr::recode_factor(unlist(test$Class), "High" = "High", "Good" = "Good", "Moderate" = "Moderate")
test$CONDITION <- dplyr::recode_factor(test$Condition, "High" = "High", "Good" = "Good", "Moderate" = "Moderate")
diatom_test <- test[test$parameter == "Phytobenthos (diatoms) - Rivers", ]
invert_test <- test[test$parameter == "Macroinvertebrates (ASPT) - Rivers", ]

table(diatom_test$Class, diatom_test$Condition)
table(invert_test$Class, invert_test$Condition)
```

# Check Years

2022 can include results from with data only from 2019. Only include locations with data from 2021 or 2022 or 2023.

```{r}
results_filtered$`Years included` <-
  gsub(",", "&", results_filtered$`Years included`)
results_filtered$check <-
  grepl("2021", results_filtered$`Years included`)

results_filtered$check[results_filtered$check == FALSE] <-
  grepl("2022", results_filtered$`Years included`[results_filtered$check == FALSE])

results_filtered$check[results_filtered$check == FALSE] <-
  grepl("2023", results_filtered$`Years included`[results_filtered$check == FALSE])

results_filtered <- results_filtered[results_filtered$check == TRUE, ]
```

# Select

```{r}
results_filtered <- results_filtered %>% select(
  "Parameter" = parameter,
  "WB ID" = wbid,
  "Location Code" = location_id,
  EQR,
  Class,
  CoCH,
  CoCG,
  CoCM,
  CoCP,
  CoCB,
  change,
  `Years included`,
  `Suit Code`,
  `Suit Text`,
  "Previous class" = Condition,
  mon_purp,
  replocs_check
)
```

Classified in 2022 classification

```{r}
# aspt_ntaxa_2022 <- 
#   read.csv("vignettes/data//aspt-ntaxa-classification-2022.csv")
# diatoms_2022 <-
# read.csv("vignettes/data//diatoms-classification-2022.csv")
# #"WBID"      "WB_NAME"   "CONDITION" "parameter"
# class_2022 <- bind_rows(aspt_ntaxa_2022, diatoms_2022)
# 
# class_2022$WB.ID <- as.character(class_2022$WB.ID)
# class_2022 <- select(class_2022, WB.ID, Parameter, "2022 Class" = Class)
# results_filtered <- left_join(results_filtered, class_2022, by = join_by(`WB ID` == WB.ID, Parameter == Parameter))
# results_filtered$`2022 Class`[is.na(results_filtered$`2022 Class`)] <- "No"
# results_filtered$`2022 Class`[results_filtered$`2022 Class` != "No"] <- "Yes"

```

Max CoC

```{r}
results_filtered$CoCH <- as.numeric(results_filtered$CoCH)
results_filtered$CoCG <- as.numeric(results_filtered$CoCG)
results_filtered$CoCM <- as.numeric(results_filtered$CoCM)
results_filtered$CoCP <- as.numeric(results_filtered$CoCP)
results_filtered$CoCB <- as.numeric(results_filtered$CoCB)

results_filtered$class_CoC <- pmax(results_filtered$CoCH,
                                 results_filtered$CoCG,
                                  results_filtered$CoCM,
                                  results_filtered$CoCP,
                                  results_filtered$CoCB
                                 )

```

# Reportable

```{r}
results_filtered$wfd_reportable <- grepl("[SM]", results_filtered$mon_purp)
results_filtered$wfd_reportable[results_filtered$wfd_reportable == TRUE | results_filtered$replocs_check == "YES"] <- "TRUE"
```

# Save

```{r}
# write.csv(results_filtered, file = "vignettes\\data\\2023-classification.csv", row.names = FALSE)

write.csv(results_filtered, file = "vignettes\\data\\2023-classification-diatoms.csv", row.names = FALSE)

write.csv(results_filtered, file = "vignettes\\data\\2023-classification-inverts.csv", row.names = FALSE)

# write.csv(data, file = "vignettes\\data\\2022-data.csv", row.names = FALSE)

sample_info <- select(data, sample_id, date_taken, year) %>%
  distinct() %>% 
  filter(year > 2016)
sample_test <- group_by(sample_info, sample_id) %>% 
  mutate(n = n())
sample_info <- mutate(sample_info, sample_id = as.character(sample_id))
results_sample <- left_join(results, 
                            sample_info, by = join_by(sample_id))

# write.csv(results_sample, file = "vignettes\\data\\sample-classification-2024.csv", row.names = FALSE)
```
