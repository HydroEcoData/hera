---
title: "Assessment Template"
output: rmarkdown::html_vignette
editor_options: 
  chunk_output_type: console
runtime: shiny
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  echo = F
)
library(hera)
library(tidyverse)
library(testthat)
```

## Welcome

This document has been created following the generic [assessment guidance](https://ecodata1.github.io/hera/articles/development_guide.html).

## Details

<!-- Create a new regulatory assessment by changing the CAPITLIZE info below: -->

```{r setup}

standard <- tibble(
  standard_short = "fim",
  quality_element = "River Invertebrates",
  parameter = "River Invertebrates",
  standard_long = "Freshwater Invertebrate Model",
  standard_reference = NA,
  aggregation = NA,
  status = "testing"
)

standard_format <- hera:::hera_format(standard = standard) # format assessment data
standard_format$standard %>%
  filter(attribute != "standard_reference") %>%
  knitr::kable()
```

## Data

```{r data}
data <- tibble(
  parameter = "River Invertebrates",
  question = "Taxon abundance",
  response = "12",
  label = "Baetidae",
  sample_id = "1234",
  location_id = "8175",
  location_description = "Eden at Kemback",
  grid_reference = "NO2342323434",
  water_body_id = "3100",
  year = "2022",
  date_taken = "2022-02-12",
  units = NA,
  min = NA,
  max = NA,
  d_f_source = 13,
  Altitude = 24,
  NGR = "NJ 53085 46834",
  logaltbar = 2.29 ,
  log_area = 2.44,
  disch_cat = 5,
  slope = 1.72,
  chalk = 0,
  clay = 0,
  hardrock = 0.946,
  limestone = 0.0435,
  peat = 0.0691
)
data
```

## Locate

Metadata required about the location

```{r}
# A list of metadata for location of sampling
location <- data %>% select(
  location_id, # optional (recommended)
  location_description,
  grid_reference
)
location <- location %>% unique()
head(location)
```

## Sample

Metadata required to assess each sample. (Excluding direct observations)

```{r}
# A list of questions and responses collected through observation
sample <- data %>% select(
  parameter,
  sample_id, # optional (recommended)
  date_taken
)
sample <- sample %>% unique()
head(sample)
```

## Observe

```{r}
questions <- data %>% select(
  question,
  response,
  label # optional (usually for taxonomic/species name)
)
questions
```


## Metrics

If applicable...

```{r indices}

indices_function <- function(data) {
  # Some calculated metric e.g. total responses in sample etc:
  library(macroinvertebrateMetrics)
  data <- data %>%
    transmute(
      SAMPLE_ID = sample_id,
      RESULT = response,
      TAXON = label
    ) %>%
    macroinvertebrateMetrics::calcWhpt()
  data <- data %>%
    transmute(
      sample_id = SAMPLE_ID,
      question = DETERMINAND,
      response = as.character(RESULT)
    )
  return(data)
}
indexes <- indices_function(data)
indexes
```

## Predictors

```{r predictors}

predictors <- whpt::demo_data %>% select(
  d_f_source,
  Altitude,
  NGR,
  logaltbar,
  log_area,
  disch_cat,
  slope,
  chalk,
  clay,
  hardrock,
  limestone,
  peat,
  date_taken,
  question,
  sample_id
)

knitr::kable(predictors)
```

## Predict

```{r prediction}
prediction_function <- function(predictors) {
  library(whpt)
  # Generates prediction based on predictors...
  prediction <- whpt::whpt_predict(predictors)
  prediction <- ungroup(prediction)
  prediction <- prediction %>%  transmute(
    sample_id = as.character(sample_id),
    location_id = data$location_id,
    response = as.character(predicted_response),
    question = index
  )
  return(prediction)
}
predictions <- prediction_function(predictors)
predictions
```

```{r together, echo=FALSE}

# All Together Now
sample_info <- data %>%
  select(names(sample), names(location)) %>%
  unique()

if (!is.null(indexes)) {
  indexes <- right_join(sample_info, indexes,
    by = c("sample_id" = "sample_id")
  )
} else {
  indexes <- data
}

predictions <- right_join(sample_info, predictions,
  by = c("location_id" = "location_id")
)
predictions$response <- as.character(predictions$response)

combined_data <- bind_rows(questions, predictions, indexes)
```


## Assessment

```{r assessment_table}

assessment_table <- tibble(
  asesssment = c(
    "high",
    "good",
    "moderate",
    "poor",
    "bad"
  ),
  value = c(
    0.80,
    0.60,
    0.40,
    0.20,
    0
  )
  # ...
  # "red" = 0.33
  # "amber" = 0.5
  # "green" = 0.66
  # ...
  # "pass" = 0.5
  # "fail" = 0.0
)

assessment_table
```

## Assess

```{r assessment}
assessment_function <- function(data, assessment_table) {
  if (nrow(data %>% filter(question == "MY_METRIC")) == 0) {
    return(NULL)
  }

  # Transform data -----------------------------------------------------------
  data <- data %>%
    select(.data$sample_id, .data$question, .data$response) %>%
    filter(.data$question %in% c("MY_PREDICTION"))
  data$response <- as.numeric(data$response)

  data <- data %>%
    distinct() %>%
    group_by(.data$sample_id) %>%
    pivot_wider(names_from = .data$question, values_from = .data$response) %>%
    ungroup()
  data[is.na(data)] <- 0

  data$eqr <- data$MY_METRIC / data$MY_PREDICTION

  class <- cut(data$eqr,
    breaks = c(1, assessment_table$value),
    labels = assessment_table$assesssment
  )

  assessments <- data.frame(
    sample_id = data$sample_id,
    class = class,
    eqr = data$eqr,
    status = data$status
  )

  assessments <- pivot_longer(assessments, -sample_id,
    names_to = "question", values_to = "response"
  )

  return(assessments)
}
assessments <- assessment_function(combined_data, assessment_table)
assessments
```


## Confidence

Confidence of assessment. 

```{r}

confidence_function <- function(data, aggregates = "sample_id") {
  confidence <- tibble(
    aggregates = NA,
    question = NA,
    response = NA
  )

  names(confidence)[1] <- aggregates[1]
}
```

## Checklist

```{r checklist}
check_list <- hera:::hera_test(standard = standard)
knitr::kable(check_list$standard_check)
```

## Update

```{r hera_update}
# No need to edit this code
model_dataframe <- hera::model_dataframe
model <- tibble(
  analysis_name = standard$parameter,
  assessment = standard$standard_long,
  standard = list(standard),
  location = list(location[1, ]),
  sample = list(sample[1, ]),
  validation_function = NA,
  indices_function = list(indices_function),
  prediction_function = list(prediction_function),
  assessment_function = list(assessment_function),
  confidence_function = list(confidence_function),
  indices = list(indexes[indexes$sample_id == indexes$sample_id[1], ]),
  assessment_table = list(assessment_table),
  questions = list(questions[1, ]),
  predictors = list(predictors[1, ]),
  predictions = list(predictions[predictions$location_id == predictions$location_id[1], ])
)

model_dataframe <- model_dataframe[model_dataframe$assessment != standard$standard_long, ]

model_dataframe <- bind_rows(model_dataframe, model)
new_model_dataframe <- model_dataframe
new_model_dataframe
usethis::use_data(model_dataframe, overwrite = TRUE)
```

## Launch app

Below is an interactive application displaying the results of your assessment.

```{r launch_app, echo=FALSE, eval=FALSE}
# No need to edit this code
launch_app(new_model_dataframe = model_dataframe, data = whpt::demo_data)
```
